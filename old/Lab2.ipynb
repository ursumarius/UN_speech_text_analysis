{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnDhddjohpdo"
   },
   "source": [
    "### <h1><center> Lab 2: Pandas and Matplotlib </center></h1>\n",
    "\n",
    "**Goals:** In this notebook we are going to experiment with practical aspects of data science, in particular the application of the (*Pandas*) (Part I) and (*Matplotlib*) (Part II) libraries. We will use a structured dataset (*Happinesss Report 2024 Dataset*).\n",
    "\n",
    "This notebook will follow contents in Chapter 3 and Chapter 4 of the [*Python Data Science Handbook*](https://jakevdp.github.io/PythonDataScienceHandbook/). Please check the book to gain some insight on how to solve the exercises and participate with questions/comments in your Werkcollege.\n",
    "\n",
    "Using the Pandas library we will:\n",
    "- Read a file and load it to a DataFrame\n",
    "- Filter out the required columns in the DataFrame\n",
    "- Summarize data based on the fields. Ex: Summing up all the rows corresponding to a certain entry in the dataset\n",
    "\n",
    "Using the Matplotlib library we will:\n",
    "- Plot data (Line plot, Scatter plot, Histogram, Error bar plot)\n",
    "\n",
    "\n",
    "Please note that Lab 2 has an extra notebook (Lab2_AuxiliaryLibraries.ipynb) to introduce auxulialiry viz libraries: Geopandas, Seaborn and NetworkX. With those libraries you can play with plotting a world map with colors representing country metrics (Geopandas), trade networks between countries (NetworkX) and apply pre-determined plotting styles (Seaborn). This can be quite helpful in Assignment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bp_eIGbchpds"
   },
   "source": [
    "<h1><center> Part I: Pandas </center></h1>\n",
    "\n",
    "In the previous Lab we used **NumPy** and we observed that this library (in particular the *ndarray* data structure) provides essential features to deal with \"well-organized\" data, typically seen in numerical tasks. Often, however, in data science projects we need the flexibility to work with labeled data (beyond the integer indexes of *ndarrays*), heterogeneous data, and with missing data. Also, NumPy offers powerful tools based on element-wise broadcasting, but we will need to perform more general operations (e.g., groupings, aggregation). **Pandas**, and in particular its *Series* and *DataFrame* objects, builds on the NumPy array structure and provides efficient tools to deal with labeled, unstructured and non-numerical data.\n",
    "\n",
    "Pandas is well suited for many different kinds of data:\n",
    "\n",
    "- Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheets.\n",
    "- Ordered and unordered time series data.\n",
    "- Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels.\n",
    "- Any other form of observational / statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure.\n",
    "\n",
    "Overall, Pandas offer many resources to deal with the tasks that data scientists have to deal with most of their time: data preparation and data cleaning.\n",
    "\n",
    "The two primary data structures of pandas are Series (1-dimensional) and DataFrame (multi-dimensional). They handle the vast majority of typical use cases in finance, statistics, social science, and many areas of engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kDKgrichpds"
   },
   "source": [
    "<h2><center> Series </center></h2>\n",
    "\n",
    "The *Series* object provided by Pandas can be seen as a generalization of the NumPy (*ndarray*).\n",
    "While in *ndarrays* the indexes are allways consecutive integers, in Series indexes can consist of values of any desired type -- think about time-series where indexes are month names instead of consecutive integers. *Series* can also be seen as a particular Python dictionary with keys that you can iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VtJXwlohpdt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "integer_numpy_array = np.arange(20,25)\n",
    "pandas_series = pd.Series(integer_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npLxBEvOhpdt"
   },
   "outputs": [],
   "source": [
    "pandas_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQ9IRdCmhpdu"
   },
   "outputs": [],
   "source": [
    "pandas_series.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVtYrqtgj3Ls"
   },
   "source": [
    "Series as a generalized NumPy array, where indexes can be any list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDb9udqdj3Ls"
   },
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0], index=[20, 40, 80, 160])\n",
    "\n",
    "data[160]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pt3eAqZ1j3Ls"
   },
   "source": [
    "Series as a specific Python dictionary, where indexes are dictionary keys that you can iterate. Contrarily to typical dictionary keys, indexes in Series are ordered structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5hC_vNcj3Ls"
   },
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou26ar_Mj3Ls"
   },
   "source": [
    "Series can be seen as a dictionary, where values can be accessed by key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlwlD5OMj3Ls"
   },
   "outputs": [],
   "source": [
    "population['New York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pZHSTw-j3Ls"
   },
   "outputs": [],
   "source": [
    "population[1::2] #slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6fTH1Pdj3Ls"
   },
   "outputs": [],
   "source": [
    "population[population > 20000000] #boolean masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpIji85Yj3Ls"
   },
   "source": [
    "This way, note that to perform indexing and slicing you can use:\n",
    "1. explicit indexes (in this case, state names)\n",
    "2. implicit indexes (integers corresponding to positions in the series)\n",
    "\n",
    "Please note, in the examples below, that slicing with explicit indexes includes the element in the upper limit of the slice; when using implicit indexes, it excludes the element in the upper limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_-8xJb-hpdv"
   },
   "outputs": [],
   "source": [
    "# explicit indexes\n",
    "population['Texas':'Florida'] #slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5fxLGSkj3Lt"
   },
   "outputs": [],
   "source": [
    "# implicit indexes\n",
    "\n",
    "population[1:3] #slicing: element in position 3 is not included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KyFE8bLj3Lt"
   },
   "source": [
    "As implicit and explicit indexing can be a source of confusion, you can explicitelly use keywords to specify whether you want to use implicit or explicit indexing.\n",
    "\n",
    "These keywords are :\n",
    "- .loc -> explicit indexing (i.e., the labels provided as indexes)\n",
    "- .iloc -> implicit indexing (i.e., the integers corresponding to positions in the Series)\n",
    "\n",
    "It is recommended that you always specity whether you are using implicit or explicit indexes, using the loc and iloc keywords.\n",
    "\n",
    "**Can you understand the differences in output between the 3 examples below?**\\\n",
    "**By default, when indexes are integers, is slicing done through implicit or explicit indexes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdGDAaw-j3Lt"
   },
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0, 0.1, 2.1], index=[3, 2, 1, 0, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClPzPLy7j3Lt"
   },
   "outputs": [],
   "source": [
    "#example 1\n",
    "data.loc[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sMr46R2j3Lt"
   },
   "outputs": [],
   "source": [
    "#example 2\n",
    "data.iloc[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "El_ABSXLj3Lt"
   },
   "outputs": [],
   "source": [
    "#example 3\n",
    "data[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3wNNTP0hpdy"
   },
   "source": [
    "**Q1: Can you create a Series where indexes are the odd numbers from 0 to 10 and values are the square of such numbers**\n",
    "\n",
    "Expected output:\n",
    "\n",
    "    1     1\n",
    "    3     9\n",
    "    5    25\n",
    "    7    49\n",
    "    9    81\n",
    "    dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gevXe1zAhpdy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ehcUxNLj3Lt"
   },
   "source": [
    "**Q2: Can you write down four ways of selecting values 9, 25 and 49?**\n",
    "1. slicing through implicit indexing\n",
    "2. slicing through explicit indexing\n",
    "3. boolean masking with conditions on values\n",
    "3. fancy indexing (remember the NumPy fancy indexing examples of Lab 1...)\n",
    "\n",
    "Expected output in all 4 cases:\n",
    "\n",
    "\n",
    "<code>3     9\n",
    "<code>5    25\n",
    "<code>7    49\n",
    "<code>dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UU3ugLG1j3Lu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJ8eDByRhpdy"
   },
   "source": [
    "<h2><center> DataFrame </center></h2>\n",
    "\n",
    "The *DataFrame* object provided by Pandas can be seen as a generalization of the 2-dimensional NumPy ndarray.\n",
    "The *DataFrame* can, alternativelly, be seen as a sequence of *Series* objects, all sharing the same index. We will see that *DataFrame* is a convenient data structure to store data and, additionally, offers useful methods to filter, transform, group and plot data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSs26bV5hpdz"
   },
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "\n",
    "area_dict = {'California': 423967,\n",
    "             'Texas': 695662,\n",
    "             'New York': 141297,\n",
    "             'Florida': 170312,\n",
    "             'Illinois': 149995}\n",
    "\n",
    "\n",
    "states = pd.DataFrame({'pop' : population_dict, 'area' : area_dict})\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9AyiYc8hpdz"
   },
   "outputs": [],
   "source": [
    "# indexing (dictionary style)\n",
    "states['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qB4ErmMyhpdz"
   },
   "outputs": [],
   "source": [
    "# indexing\n",
    "# notice that first we access columns and then rows..\n",
    "\n",
    "states['area']['Florida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iC4QMA1Fhpd0"
   },
   "outputs": [],
   "source": [
    "# indexing through NumPy ndarray of values: Florida=3, area=1\n",
    "# notice that first we access rows and then columns..\n",
    "\n",
    "states.values[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDPHsXarhpd0"
   },
   "outputs": [],
   "source": [
    "# slicing\n",
    "\n",
    "states['area']['Texas':'Florida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ozbtZk1hpd0"
   },
   "outputs": [],
   "source": [
    "# by default, slicing iterates over rows and the stop element in the slice is included\n",
    "# (as in the Series examples above)\n",
    "\n",
    "states['Texas':'Florida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mCzv72Jhpd0"
   },
   "outputs": [],
   "source": [
    "# fancy indexing\n",
    "\n",
    "states['area'].iloc[[1,3,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaNqvipghpd1"
   },
   "outputs": [],
   "source": [
    "# masking\n",
    "\n",
    "states[states['area'] > 180000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvGuq9hyhpd1"
   },
   "outputs": [],
   "source": [
    "# add new column\n",
    "\n",
    "states['density'] = states['pop'] / states['area']\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTKgEn8Fhpd1"
   },
   "source": [
    "As accessing elements by dictionary-style, array-explicit-style or array-implicit-style can be confusing, there are specific keywords you can use to decide the type of indexing. As in the Series examples above, loc and iloc can be used to specity implicit or explicit indexing. These keywords also enforce array-style indexing (e.g., a single index accesses rows instead of columns)\n",
    "\n",
    "\n",
    "- .loc -> array-style indexing, explicit indexing using labels\n",
    "- .iloc -> array-style indexing, implicit indexing using positions\n",
    "\n",
    "**In the next examples: three ways of accessing the area of Florida... can you understand the differences?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7T46mVJyhpd1"
   },
   "outputs": [],
   "source": [
    "states.loc['Florida','area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOgiLpUHhpd2"
   },
   "outputs": [],
   "source": [
    "states.iloc[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4wRoWc5hpd2"
   },
   "outputs": [],
   "source": [
    "states['area']['Florida']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LueD9HQ_hpd2"
   },
   "source": [
    "**Q3: Can you calculate the difference in population size between Texas and New York?**\\\n",
    "**Try to answer using the 3 different types of DataFrame indexing introduced above.**\n",
    "\n",
    "Expected result in any of the possibilities: 6797066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_SHXD_Ohpd2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImjOsLKmhpd3"
   },
   "source": [
    "loc and iloc are also convinient to desambiguate indexing when indexes are integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovTjIvK4hpd3"
   },
   "outputs": [],
   "source": [
    "data = pd.Series(['d', 'c', 'b', 'a'], index=[3, 2, 1, 0])\n",
    "\n",
    "data[0] # will the output be 'a' or 'd'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skTgjCDnhpd3"
   },
   "outputs": [],
   "source": [
    "data[1:3] #-> -> implicit indexing used; the stop element in the slice is not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whJhcQflj3Lx"
   },
   "outputs": [],
   "source": [
    "data.iloc[1:3] #-> -> same as using iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaN4C-_fj3Lx"
   },
   "outputs": [],
   "source": [
    "data.loc[3:1] #-> -> explicit indexing can also be used; to avoid confusion, always use loc or iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7G-pu5XChpd3"
   },
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vo10S7nshpd3"
   },
   "outputs": [],
   "source": [
    "data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jxpyub4nhpd4"
   },
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "\n",
    "area_dict = {'California': 423967,\n",
    "             'Texas': 695662,\n",
    "             'New York': 141297,\n",
    "             'Florida': 170312,\n",
    "             'Illinois': 149995}\n",
    "\n",
    "\n",
    "states = pd.DataFrame({'pop' : population_dict, 'area' : area_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkeWSzVNhpd4"
   },
   "outputs": [],
   "source": [
    "states.loc['Florida']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyncK4pjhpd4"
   },
   "source": [
    "**Q4: Create a new column in the DataFrame *states* that contains a boolean to indicate if population size is higher than 20000000**\n",
    "\n",
    "Expected outcome: DataFrame with extra column named \"popSize2000\" with True in indexes California and Texas and False otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rouadnQahpd4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5nqswWIhpd5"
   },
   "source": [
    "**Q5: Select the states with density (i.e., pop/area) higher than 100**\n",
    "\n",
    "Expected outcome: DataFrame with two rows (New York and Florida) and three columns (pop, area, popSize2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtVk8Ug4hpd5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2oDdoc1j3Lx"
   },
   "source": [
    "We can apply most aggregation functions (that we were used to apply with NumPy) to Pandas DataFrames. We can aggregate along either rows or columns. Below one example of calculating the mean population across states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMineALQj3Lx"
   },
   "outputs": [],
   "source": [
    "states['pop'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fm8qv5GZhpd6"
   },
   "source": [
    "**Q6: Select the area of the largest state; after that, print the name of the largest state.**\n",
    "\n",
    "Tip: check the Secion \"*Simple Aggregation in Pandas*\" of the Python Data Science Handbook\n",
    "\n",
    "The question asks for the area of the largest state. To print the name of the largest state the method [idxmax](https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.idxmax.html) can be handy... **Can you use idxmax to print the name of the largest state?**\n",
    "\n",
    "Expetected output:\n",
    "\n",
    "695662\n",
    "\n",
    "Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRFWXjrhhpd6",
    "outputId": "fe524beb-c5ef-4dce-f285-63536b7fa424"
   },
   "outputs": [],
   "source": [
    "# applying universal functions: indices are aligned and perserved\n",
    "A = pd.DataFrame(np.ones((2, 2)), columns=list('AB'))\n",
    "B = pd.DataFrame(np.arange(9).reshape(3,3), columns=list('BAC'))\n",
    "C = A + B\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNveaBckj3Ly"
   },
   "source": [
    "**Q7: Consider that, for the operations you would like to perform, NaN can be substituted by 1. How can you substitute all NaN by 1 in DataFrame C?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaCdHBtHj3Ly"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RZKMlrUhpd6"
   },
   "source": [
    "Pandas provides useful methods to deal with missing items. Note that when adding DataFrame A and B there is a column and row of NaN added; that is because DataFrame A is missing row 2 column C, both present in DataFrame B. Below, see how convenient it is to replace NaN with a default value when applying the operation add — the NaN are substituted in DataFrame A, to guarantee index/column alignment between A and B before the operation add is applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzfpiYsKhpd6"
   },
   "outputs": [],
   "source": [
    "dfC = A.add(B, fill_value=-100)\n",
    "dfC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB-g4W-9hpd7"
   },
   "source": [
    "**Q8: Can you calculate the sum of COLUMNS A, B and C of dataFrame dfC ?**\n",
    "\n",
    "Expected outcome:\n",
    "\n",
    "    A    -86.0\n",
    "    B    -89.0\n",
    "    C   -285.0\n",
    "    dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7OioU8fhpd7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5gpLtmahpd7"
   },
   "source": [
    "**Q9: Can you calculate the mean of ROWS indexed by 0, 1 and 2 of DataFrame dfC ?**\n",
    "\n",
    "Expected outcome:\n",
    "\n",
    "    0   -31.666667\n",
    "    1   -28.666667\n",
    "    2   -93.000000\n",
    "    dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NATlApJPhpd7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKdqVA34hpd7"
   },
   "source": [
    "<h2><center> Working with a real dataset </center></h2>\n",
    "\n",
    "In the next examples we are going to read and use a structured dataset (*DataForTable2.1.xls*) which corresponds to Happiness World Report 2024. Make sure to have *DataForTable2.1.xls* in the same folder as this Jupyter Notebook. This dataset will be useful also in Assignment 1.\n",
    "\n",
    "You can find more info about the meaning of each column in the *DataForTable2.1.xls* dataset [here] (check the Statistical Appendix)(https://worldhappiness.report/ed/2024/#appendices-and-data).\n",
    "\n",
    "Importantly, *Life Ladder* corresponds to the happiness index.\n",
    "\n",
    "Some clarifications regarding the code below:\n",
    "- we are importing Excel data\n",
    "- index_col=[0,1] means that we will use as Index column 0 and column 1 of the excel file\n",
    "- Note that we are specifying 2 Indexes. This means we will have a DataFrame with a MultiIndex (examples provided below); please read section \"Hierarchichal Indexing\" of the recommended [book](\"https://jakevdp.github.io/PythonDataScienceHandbook/03.05-hierarchical-indexing.html\") for extra details and syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GavQrw7hpd8"
   },
   "outputs": [],
   "source": [
    "happinessdataframe = pd.read_excel('DataForTable2.1.xls', index_col=[0,1])\n",
    "happinessdataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApQBjveehpd8"
   },
   "source": [
    "**Q10: Can you select data corresponding to The Netherlands, from 2005 to 2023?**\n",
    "\n",
    "Expected output: DataFrame with 17 rows (2005 - 2023) and 9 columns (all columns in the previous DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLKzrCVhhpd8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Dvu4S-Fhpd9"
   },
   "source": [
    "**Q11: Can you grop each row by Year and, for each year, present the mean of each column?**\n",
    "\n",
    "Expected output: same as above but grouped by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viTzkR5nhpd9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOO3MvDghpd-"
   },
   "source": [
    "**Q12: Can you group data by year and, for each year, present the mean and variance for the 'Healthy life expectancy at birth'?**\n",
    "\n",
    "Expected outcome: DataFrame with 19 rows (2005 - 2023) and 2 columns (mean, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zf8aqtlyhpd-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Vv75dDVj3Lz"
   },
   "source": [
    "idxmax() can be applied to a DataFrame to obtain the maximum for each group; in the example below, we select the Index (Country, year) where the maximum 'Healthy life expectancy at birth' is observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxQZhRNhhpd-"
   },
   "outputs": [],
   "source": [
    "happinessdataframe['Healthy life expectancy at birth'][0:-1].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhaGIN5Ahpd-"
   },
   "source": [
    "**Q13: Which was the happiest country in 2023? (using idxmax and 1 line of code)**\n",
    "\n",
    "Note: By happiest, we mean the country with the highest value in *Life Ladder.*\n",
    "\n",
    "Expected outcome: 'Finland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzT71ikWhpd-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiJA0fMDhpd_"
   },
   "source": [
    "**Q14: What was the Healthy life expectancy at birth in 2023, by country?**\n",
    "\n",
    "Expected outcome:\n",
    "\n",
    "    Country name\n",
    "    Afghanistan    55.200001\n",
    "    Albania        69.199997\n",
    "    Argentina      67.300003\n",
    "    Armenia        68.199997\n",
    "    Australia      71.199997\n",
    "                     ...    \n",
    "    Venezuela      63.700001\n",
    "    Vietnam        65.699997\n",
    "    Yemen          56.599998\n",
    "    Zambia         56.099998\n",
    "    Zimbabwe       55.000000\n",
    "    Name: Healthy life expectancy at birth, Length: 138, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLj6TLK3hpd_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmLgDEXYhpd_"
   },
   "source": [
    "**Q15: What was the average GDP of the Netherlands from 2013 to 2023 (inclusive)?**\n",
    "\n",
    "Expected output: 10.9168.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpgewVn-hpd_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_bjVCIOhpeA"
   },
   "source": [
    "<h2><center> Matplotlib </center></h2>\n",
    "\n",
    "Matplotlib is the package for visualization in Python. We will now use the previous dataset and produce some visualizations. Just as we use the <code>np</code> shorthand for NumPy and the <code>pd</code> shorthand for Pandas, we will use <code>mpl</code> and <code>plt</code> as standard shorthands for Matplotlib imports.\n",
    "\n",
    "A potentially confusing feature of Matplotlib is its dual interfaces: a MATLAB-style state-based interface, and a more powerful object-oriented interface.\n",
    "\n",
    "In our Labs we will mainly use the object-oriented interface as it provides greater flexibility. In practice, we will always call methods over an object Axes.\n",
    "\n",
    "We will first see some plot types and then plot quantities of interest related with the Happiness Report 2024 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHwQjxkphpeA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First create a grid of plots\n",
    "# ax will be an array of two Axes objects\n",
    "fig, ax = plt.subplots(2)\n",
    "\n",
    "x = np.arange(0,10,0.1)\n",
    "\n",
    "# Call plot() method on the appropriate object\n",
    "ax[0].plot(x, np.sin(x))\n",
    "ax[1].plot(x, np.cos(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0jzCwkuhpeA"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.linspace(0, 10, 30)\n",
    "y = np.sin(x)\n",
    "\n",
    "ax.plot(x, y, 'o', color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_uq9MyrhpeB"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.linspace(0, 10, 50)\n",
    "dy = 0.8\n",
    "y = np.sin(x) + dy * np.random.randn(50)\n",
    "\n",
    "ax.errorbar(x, y, yerr=dy, fmt='o', color='black',\n",
    "             ecolor='lightgray', elinewidth=3, capsize=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQ1eXVwjhpeB"
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "\n",
    "data = np.random.randn(1000)\n",
    "\n",
    "ax.hist(data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeeJ9LOShpeB"
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "\n",
    "mean = [0, 0]\n",
    "cov = [[1, 1], [1, 2]]\n",
    "x, y = np.random.multivariate_normal(mean, cov, 10000).T\n",
    "\n",
    "plot2d = ax.hist2d(x, y, bins=30, cmap='Blues')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5AcidpqhpeB"
   },
   "source": [
    "<h2><center> Working with a real dataset </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeqN31cnj3L3"
   },
   "source": [
    "How did the world mean GDP evolved from 2006 to 2021? You will see one answer to this question using matplotlib explicitely, and another using the interface to plot provided by Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPnlsis7j3L3"
   },
   "outputs": [],
   "source": [
    "happinessdataframe.groupby('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0OH4CUGhpeB"
   },
   "outputs": [],
   "source": [
    "# using matplotlib explicitly\n",
    "x = happinessdataframe.groupby('year').mean()['Log GDP per capita']\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6x11eSQhpeC"
   },
   "outputs": [],
   "source": [
    "# using .plot() applied to DataFrame\n",
    "# this is a shortcut for the code in the previous cell\n",
    "x = happinessdataframe.groupby('year').mean()['Log GDP per capita']\n",
    "x.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4GKBF-bj3MD"
   },
   "source": [
    "How do countries distribute in terms of GDP and corruption, in 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXPXObvjhpeC"
   },
   "outputs": [],
   "source": [
    "x = happinessdataframe.loc(axis=0)[:,2020][[\"Log GDP per capita\",\"Perceptions of corruption\"]]\n",
    "x = happinessdataframe.loc(axis=0)[:,2020][[\"Log GDP per capita\",\"Perceptions of corruption\"]]\n",
    "\n",
    "x.plot.scatter(x=\"Log GDP per capita\", y=\"Perceptions of corruption\",c='black')\n",
    "plt.show()\n",
    "\n",
    "happinessdataframe.loc[:,2020,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WasOp4dj3MD"
   },
   "source": [
    "What was the mean happiness over the years? How much does it vary across countries, per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLWk9HmNhpeC"
   },
   "outputs": [],
   "source": [
    "x = happinessdataframe.groupby('year').aggregate(\"mean\")[\"Life Ladder\"]\n",
    "dy = happinessdataframe.groupby('year').aggregate(\"std\")[\"Life Ladder\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.errorbar(x.index, x.values, yerr=dy, fmt='o', color='black',\n",
    "             ecolor='lightgray', elinewidth=3, capsize=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-ExLgtsj3MD"
   },
   "source": [
    "**Q16: Can you create an histogram to reprsent how countries distributed in terms of Life expectancy in 2014?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gTyv_hkhpeC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT8YjYcehpeD"
   },
   "source": [
    "**Q17: What was the relationship between GDP and Healthy life expectancy at birth in 2014? — produce a Scatter plot to visualize this relationship**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xt_w9y2hpeD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TPcE9pGhpeD"
   },
   "source": [
    "**Q18: How does the distribution of life expectancy in the top 50% happiest countries compare with the bottom 50%, considering all years?**\n",
    "\n",
    "Suggestion: show this relationship in a plot with two histograms, one for the top 50% happiest countries and another for the bottom 50%.\n",
    "\n",
    "Tips:\n",
    "- Check Figure 4-37, and respective code, of the book Python Data Science Handbook\n",
    "- Each histogram corresponds to the countries with Life Ladder highest than the median : <code>happinessdataframe[\"Life Ladder\"].median()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GKGNqPOhpeD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
